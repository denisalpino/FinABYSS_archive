Перед началом практической реализации на основе предварительного семантического анализа и
структурного проектирования была проведена всесторонняя аналитическая оценка, призванная
выявить и формализовать технические ограничения, влияющие на архитектуру FinABYSS. В результате
было выделено пять ключевых проблемных областей, из которых трем удалось предложить устойчивые
решения, а две менее критичные оставлены для последующих исследований.

\textbf{Дедубликация текстов.} Дедубликация является необходимым элементом конвейера
текстового анализа тональности, поскольку финансовые сигналы, распространяющиеся с задержкой,
могут неоднократно попадать в корпус, и их многократное учёт искаженяет результаты
прогнозирования. Так, первичная публикация о нарушениях в выдаче ипотечных кредитов
в сентябре 2008 г. формировала сильный негативный сентимент в момент возникновения события,
в то время как её републикации через годы, сопровождающие ретроспективные обзоры, не оказывают
аналогичного влияния на цену активов. Подобная дискретность временного контекста не учитывается
при классической текстовой дедубликации, основанной на лингвистическом или синтаксическом сходстве.

Две новости могут иметь практически полное сходство текста и при этом нести кардинально различные
смысловые оттенки. Теоретический пример --- если бы в исходной статье о штрафе Citi Group
(Раздел \ref{sec:practical_importance}), «79 млн» было бы ошибочно заменено на «79 тыс.», --- это бы
повлекло за собой принципиально разный сентимент и потенциально противоположное торговое решение.

Особая категория дублирующих материалов представлена коррекциями на платформе Yahoo! Finance. Такие
публикации начинаются с маркера «/CORRECTION/», затем в статье указывают на исправленные фрагменты и
повторяют основной текст почти дословно. Линейная дедубликация на уровне строк или $n$-грамм в таких
случаях удаляет последнюю версию, что нарушает логику потокового анализа.

Таким образом, дедубликация в финансовом медиапотоке должна отвечать двум требованиям: во-первых,
различать семантически эквивалентные, но контекстуально разных по времени публикации; во-вторых,
корректно обрабатывать «correction»-версии, извлекая непересекающуюся семантику, если она значимо
отличается от предыдущей версии. Каждый документ следует считать уникальным, если он содержит новую
информацию, даже при высокой доле текстового совпадения.

Поскольку в задаче отсутствует исходная разметка, требуется формальная постановка проблемы семантической
дедубликации, выходящей за рамки простого текстового сравнения. Семантическое пространство текстов,
в отличие от лексического, непрерывно и неограниченно, и поэтому для проверки уникальности одного
документа недостаточно попарного сопоставления строк или текстов посредством косинусного расстояния:
необходимо оперировать объемами векторных представлений и учитывать распределение идей в более широком
контексте.

Полное описание математической формулировки задачи и предложенного аналитического решения представлено
в разделе \ref{sec:semantic_deduplication}. Именно там даётся строгое определение семантической уникальности,
приводится алгоритм обнаружения близких по смыслу, но различающихся по информационной ценности документов.

\textbf{Вычислительные ресурсы.} Для обучения моделей на больших данных требуется крайне мощная вычислительная
инфраструктура. Так, одна модель FinBERT обучалась на четырех NVIDIA Tesla P100 в течение двух суток на 5 миллиардах
токенов \parencite{Yang2020FinBERT}. Стоит уточнить, что здесь приводится время обучения лишь одной модели, а в процессе
экспериментирования обычно обучается еще несколько моделей. Говоря о ModernBERT --- он был обучен на восьми NVIDIA
H100 за 10 суток, а общий объем корпуса составил около 3 триллионов токенов \parencite{Warner2024ModernBERT}.

В контексте нашего исследования в качестве базовой модели используется именно ModernBERT, соответственно ориентироваться
стоит именно на него. В ходе исследования был собран корпус из приблизительно 1 миллиарда токенов, что хоть и меньше
корпуса ModernBERT, однако хватило бы для доменно-адаптированного предобучения, то есть дополнительной четвертой
стадии предобучения \parencite{Warner2024ModernBERT, gururangan2020DAPT}.

Обучение даже базовой модели ModernBERT требует крайне мощного вычислительного оборудования. Минимальные требования
NVIDIA Tesla T4 из серверного сегмента и NVIDIA RTX 3090 --- из пользовательского \parencite{Warner2024ModernBERT}. Тем не менее,
в контексте исследования была доступна только NVIDIA RTX 3060, на которой было бы невозможно обчинить ModernBERT.
Поэтому, из-за труднодоступности вычислительных ресурсов, в контексте исследования используется базовая версия
ModernBERT тонко настроенная для задачи кластеризации векторных представлений.

\textbf{Ограниченность данных.} Отсутствие репрезентативного текстового корпуса в финансовом домене стало одной
из ключевых проблем данного исследования. При попытках найти открытые наборы данных на платформах HuggingFace,
Kaggle, GitHub и аналогичных ресурсах выяснилось, что доступные финансовые корпуса либо удалены по причинам
нарушения авторских прав, либо закрыты для общего пользования, либо представляют собой слишком короткие фрагменты
текста, непригодные для тематического моделирования и сентимент-анализа
\parencite{FiQA2018SA, Malo2014FPB, daudert2022multi, FSA2020problems, wiebe2005annotating}. Кроме того, многие
из оставшихся наборов предназначены исключительно для тонкой настройки нейросетевых моделей (fine-tuning), но
не содержат  необходимого объёма или разнообразия данных.

Самостоятельный сбор финансовых новостных статей осложняется тем, что ключевые источники разрознены и зачастую
противодействуют массовому скрейпингу. Лишь немногие провайдеры предоставляют доступ к платным и дорогостоящим
API (например, X, ранее Twitter), где цены на исторические данные могут исчисляться тысячами долларов. При этом
новостные площадки обычно фокусируются на узких сегментах отраслевого контента, что делает корпус с одного
источника предвзятым и фрагментарным.

С финансовой точки зрения важна не только широта охвата, но и наличие достоверных метаданных: временных меток,
информации об авторе и других. Многие сайты лишены открытых архивов, предоставляют лишь RSS-ленты, а часть ресурсов
попросту не размещает даты публикации в HTML, что делает автоматизированный парсинг невозможным без глубокого
анализа и регулярного обновления скриптов. Различные структуры HTML-шаблонов и динамические генераторы контента
(JavaScript-рендеринг) увеличивают сложность разработки конвейеров извлечения данных.

Таким образом, попытка собрать по-настоящему репрезентативный корпус потребует интеграции множества источников
с разнородными схемами сайтов, что приводит к высокой технической нагрузке. Ориентация на один-единственный
поставщик данных рискует ввести дисбаланс в тематических и региональных представлениях финансовых событий. При
этом существующие платные альтернативы (например, коммерческие датасеты News от Bright
Data) оцениваются в несколько тысяч долларов
за объём, идентичный с собранным ходе исследования корпусом, что выходит за рамки бюджетных и исследовательских
ограничений проекта.

Следовательно, отсутствие открытых, крупных и однородных финансовых корпусов остаётся серьёзным препятствием
для создания масштабируемых и надёжных моделей тематического моделирования и анализа тональности в сфере финансов.
В дальнейшем разделе \ref{sec:data_collecting} описывается выбранный компромиссный подход к сбору и агрегации
данных, учитывающий выявленные ограничения и требования к качеству корпуса.

\textbf{Ограниченность контекстного окна.} Базовая версия модели ModernBERT обеспечивает контекстное окно
в 8 192 токена, что существенно превосходит традиционные BERT-подобные модели с ограничением в 512 токенов
\parencite{devlin2019BERT,Warner2024ModernBERT}. Однако даже при таком расширенном ресурсе финансовые документы
формата 10-K и 10-Q, зачастую превышающие десятки страниц, не умещаются полностью. Хотя существуют техники
скользящего окна или фрагментирования текста на перекрывающиеся чанки, они выходят за рамки исходной задачи
оценки «из коробки» возможностей современных LLM. В контексте данного исследования было принято решение
ограничиться анализом новостных статей, размеры которых вписываются в 8 192 токена, а многостраничные аналитические
отчёты не рассматривать. Это позволило сохранить фокус на сопоставлении эмбеддинговых и тематических моделей
без усложнения препроцессинга за счет агрегирования отрывков длинных документов.

\textbf{Нерелевантность существующих бенчмарков.} Сравнение производительности модели ModernBERT и её
доменно-адаптированной версии на общепринятом бенчмарке FLUE кажется естественным шагом для оценивания прогресса.
Однако датасеты FLUE состоят преимущественно из коротких фрагментов (до 512 токенов), предназначенных для типовых
заданий понимания текста \parencite{FLANG2022FLUE}. Поскольку эти датасеты заточены под 512-токенное окно, они не отражают
преимуществ расширенного контекста ModernBERT и, наоборот, будут занижать его итоговые показатели. Таким образом,
использование FLUE в текущем исследовании приведёт к искаженному восприятию качеств модели: задачи на коротких текстах
не демонстрируют её способность захватывать долгосрочные зависимости и синтезировать информацию из больших объёмов данных.

Обе проблемы — ограниченность контекстного окна при анализе длинных документов и нерепрезентативность
стандартных 512-токеновых бенчмарков — диктуют необходимость создания специализированных методик предобработки
и валидации, адаптированных под финансовый домен. За исключением данных двух проблем, все остальные были разрешены
и их решения предлагаются в дальнейших разделах работы.
