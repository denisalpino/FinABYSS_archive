\subsubsection{Прогнозирование стоимости}
Существует множество подходов, демонстрирующих эффективность прогнозирования стоимости активов с помощью
глубоких нейронных сетей. Наиболее распространёнными в этой задаче являются рекуррентные нейронные сети
(Recurrent Neural Networks, RNN), тогда как сверточные нейронные сети (Convolutional Neural Networks, CNN)
используются преимущественно в качестве вспомогательного компонента.

Наиболее характерным представителем семейства RNN является архитектура долгой кратковременной памяти
(Long Short-Term Memory, LSTM) \parencite{Hochreiter1997LSTM}, часто применяемая для прогнозирования
цен. Её модификации, такие как двунаправленная LSTM (Bidirectional LSTM, Bi-LSTM) и гибридные модели
CNN-LSTM, также показывают высокую результативность. Более того, с появлением трансформерной архитектуры
\parencite{vaswani2017attention} всё активнее исследуются методы её адаптации к специфике временных рядов
\parencite{wen2022transformers}.

В числе последних экспериментов особенно выделяются:

\begin{itemize}
    \item репозиторий, в котором демонстрируется потенциал трансформерной архитектуры на примере прогнозирования
    цены Биткоина\footnote{Bitcoin Price Prediction Using Transformers [Electronic resource] //
    baruch1192. --- 2025 --- URL: \url{https://github.com/baruch1192/-Bitcoin-Price-Prediction-Using-Transformers} (Дата обращения: 11.01.2025).};
    \item исследование, сравнивающее производительность моделей Bi-LSTM, гибридных CNN-Bi-LSTM и трансформера
    при прогнозировании стоимости акций IBM\footnote{CapMarket [Electronic resource] //
    JanSchm. --- 2025 --- URL: \url{https://github.com/JanSchm/CapMarket} (Дата обращения: 18.12.2024).};
    \item торговый робот на базе LSTM, ориентированный на извлечение краткосрочной прибыли в боковом движении
    цены актива CGEN, показавший при бэктестинге доходность в размере 4\% депозита за сутки
    \footnote{Stock Price Prediction with a Bot [Electronic resource] //
    roeeben. --- 2025 --- URL: \url{https://github.com/roeeben/Stock-Price-Prediction-With-a-Bot} (Дата обращения: 27.12.2024).}.
\end{itemize}



Тем не менее отдельные модели, будь то LSTM или методы на основе деревьев решений, обладают ограниченной
адаптивностью при смене рыночных режимов и плохо реагируют на их динамику \parencite{Vukovi2024}.
Несмотря на очевидность этого факта, исследователи нередко недооценивают его значение. Согласно теории
эффективного рынка (Efficient Market Theory, EMT), предложенной Фама в 1970 году, цены активов отражают
всю доступную рыночную информацию, что ставит под сомнение возможность точного прогнозирования на основе
лишь исторических количественных показателей --- цены открытия, закратия, максимума, минимума (Open High
Low Close, OHLC), объёма торгов и классических индикаторов.

К тому же большинство моделей не учитывают такие тонкие аспекты, как заявки лимитного порядка, влияние
других торговых роботов, а также качественную внебиржевую информацию. Новейшие исследования показывают,
что интеграция анализа информационного поля за пределами биржи в прогнозные модели заметно повышает качество
предсказаний, о чём будет подробно рассказано в последующих подразделах.

\subsubsection{Анализ тональности}
Как отмечалось во введении, появление трансформерной архитектуры позволило моделям глубокого обучения
достичь значительного прогресса в понимании естественного языка (Natural Language Understanding, NLU).
Это имеет особую ценность для финансовой сферы, где традиционные количественные данные недостаточны
для точного прогнозирования.

Еще до распространения современных языковых моделей для анализа тональности текста (Sentiment Analysis,
SA) применялись LSTM-модели, ULMfit, авторегрессионные сети и другие методы
\parencite{Hochreiter1997LSTM, howard2018ULMFIT}. Например, в одном исследовании сравнивали
авторегрессионную модель без учета тональности с аналогичной моделью, интегрировавшей
тональностные признаки. Результаты показали, что в 77.8\% случаев модель с учетом тональности
превосходила версию, обученную только на количественных данных \parencite{NNAR2019}.

Современные предобученные трансформерные модели, известные как большие языковые модели (Large Language Model,
LLM), открывают новые возможности для финансового прогнозирования. Наиболее очевидное применение ---
анализ тональности новостей. Для этого требуется сбор значительного объема текстовых данных с последующей
разметкой. Метки классов обычно включают три категории: -1 (негативный), 0 (нейтральный) и 1 (позитивный)
\parencite{SA2020taxonomy}.

Ручная разметка предполагает привлечение отраслевых экспертов, способных оценить влияние текста
на финансовые рынки. Для повышения качества данных применяется метод перекрестного консенсуса \parencite{consensus1997bogdan}:
несколько экспертов независимо аннотируют одни и те же тексты, после чего метки согласуются.
Именно этот подход использовался при создании популярного датасета FinancialPhraseBank \parencite{Malo2014FPB} для тонкой
настройки моделей под задачу финансового анализа тональностей (Financial SA, FSA).

Алгоритмические методы, основанные на динамике стоимости активов, менее распространены из-за
субъективности и нестабильности. В частности по той причине, что сложно определить пороговое
значение изменения цены для классификации тональности и гарантировать, что фактический прирост
не обусловлен любым другим фактором.

После разметки данных, на что уходит большая часть ресурсов, выполняется тонкая настройка
предобученных языковых моделей путем модификации весов на последних слоях нейросети.

Таксономия SA включает три уровня \parencite{SA2020taxonomy}:

\begin{itemize}
    \item \textbf{Документальный уровень.} Тональность оценивается для всего документа (новости, отчета и т.д.).
    Данный уровень предполагает наличие в документе мнений об одной сущности, что редко соответствует реальности.
    Более того, существует и техническое ограничение --- современные трансформеры технически не способны
    обрабатывать многостраничные документы (например, отчеты 10-K) или новостные статьи, вследствие ограниченных
    возможностей обработки токенов. Тем не менее, в последнее время стали появляться модели, способствующие обработки
    хотя бы новостных статей, однако отчеты все еще не могут быть обработаны ими.
    \item \textbf{Уровень предложений.} Тональность относится к одному или нескольким предложениям (обычно 1-8 предложений),
    при этом сохраняется предпосылка об одном субъекте. Именно работы данного уровня преобладают в общем числе благодаря
    доступности датасетов и технической совместимости с современными LLM, из которых практически все способны обработать
    тексты такого размера. Типичные источники --- заголовки новостей, публикации в социальных сетях X (бывший Twitter) и Reddit.
    \item \textbf{Аспектный уровень (Aspect-Based SA, ABSA).} Выявление тональности по отношению к отдельным аспектам сущности.
    ABSA на данный момент является наиболее  продвинутым уровнем, который довольно часто рассматривают как отдельную и достаточно
    обширную область. ABSA включает четыре подзадачи: извлечение аспектов, определение их полярности, категоризация аспектов
    и оценка полярности категорий. Отдельно выделяют таргетированный ABSA, который допускает несколько субъектов, но предполагает
    не более одного сентимента на каждого из них. Более подробно ABSA рассматривается в \hyperref[sec:absa]{Section 1.1.3}.
\end{itemize}

Большинство методов SA требуют разметки текстов, что является существенным недостатком, в ввиду больших ресурсных затрат,
а также имеет естественные ограничения:

\begin{itemize}
    \item Не существует универсального и точного определения тональности, подходящего для каждой задачи. Это вынуждает формулировать
    уникальное определение в ходе решения практических задач, что затруднительно из-за многочисленности паттернов
    и сценариев, встречающихся в текстах.
    \item Невозможно без кратного увеличения затрат на контроль (например, при помощи метода перекрёстного консенсуса
    \parencite{consensus1997bogdan}) обеспечить надежность и объективность оценок, так как на качество разметки
    сильно сказывается человеческий фактор.
\end{itemize}

Как было отмечено, постановка SA может несколько отклоняться от своей классической постановки в контексте различных доменов.
Так, особенностью FSA является то, что он фокусируется не исключительно на обособленных текстах, но так же и на количественной
информации, которая в финансовых статьях крайне много \parencite{FSA2024techniques}.

Тем не менее, FSA терпит неудачи в нескольких типовых сценариях среди которых: нереальные настроения (условные настроения,
сослагательное наклонение, повелительное наклонение), риторика (негативные заявления, персонификация, сарказм), зависимые
мнения, неопределенные аспекты, нераспознанные слова (жаргонизм, микротекст, сущности) и external references (то есть
отсылки к тем знаниям, которые не заключены в модель) \parencite{FSA2020problems}.

\subsubsection{Аспектный анализ}
\label{sec:absa}
ABSA представляет собой специализированную задачу выявления и оценки сентимента по отношению к конкретным
«аспектам» --- характеристикам или свойствам рассматриваемого объекта. В финансовой сфере такими аспектами
могут выступать рисковые факторы, кредитная политика, макроэкономические индикаторы и другие элементы,
упоминаемые в публикациях. Классический подход к ABSA включает три этапа: выделение аспектов из текста,
определение полярности сентимента по каждому аспекту, и агрегацию результатов для построения итоговой
картины мнений экспертов или рынка .

Параллельно с развитием ABSA в лингвистическом сообществе активно развалось тематическое моделирование,
главной целью которого является выявление скрытых «тем» (topics) в корпусах документов. Одним из первых
и наиболее влиятельных методов стал Latent Dirichlet Allocation (LDA) \parencite{LDA2003}, где темы
формулируются как распределения слов, а документы рассматриваются как смеси таких распределений. В контексте
финансовых текстов LDA позволяет выделять основные направления обсуждения (например, «монетарная политика»,
«корпоративные риски» и т.д.), но испытывает сложности с моделированием синтагматических связей и динамичной
лексики.

На стыке эмбеддинговых моделей и тематического анализа сформировалась идея top2vec \parencite{angelov2020top2vec},
согласно которой темы представляются в том же векторном пространстве, что и слова, что позволяет объединить
преимущества распределённых представлений и тематических структур. Далее эволюция привела к появлению BERTopic
\parencite{BERTopic2022}, где для построения тем используются плотностные алгоритмы поверх эмбеддингов, а зате
 для каждого кластера извлекаются наиболее характерные ключевые слова. Эта модель демонстрирует высокую
 адаптивность к изменениям лексики и позволяет работать с динамическими, даже мультиязычными корпусами.

Связь между ABSA и тематическим моделированием очевидна: аспекты в широком смысле являются темами, по отношению
к которым измеряется сентимент. В традиционном ABSA аспекты задаются или извлекаются на основе лингвистических
паттернов (например, правилами на зависимостях или словарями), тогда как тематическое моделирование открывает
путь к автоматическому выявлению аспектов как скрытых латентных переменных. Преимущество такого подхода
в финансовом домене заключается в том, что заранее неизвестное множество аспектов («тем») может быть извлечено
без ручной разметки, после чего к выявленным кластерам документов применяется стандартная процедура оценки
сентимента (например, с помощью LLM), что позволяет получать более полный и интерпретируемый анализ мнений рынка.

Таким образом, в рамках данной работы аспекты рассматриваются как темы в тематическом моделировании. А работа
предлагает способ первоначальной кластеризации векторных представлений, которая формирует «тематические кластеры»,
для того, чтобы агрегировать по ним сентимент. Такое объединение позволяет (1) выявлять как глобальные тренды,
так и локальные, нишевые аспекты финансового рынка, (2) минимизировать необходимость ручной разметки аспектов,
и (3) обеспечить интерпретируемость результатов за счёт явной привязки сентимента к темам, выраженным через
ключевые термины каждого кластера. Это сочетание взяло лучшее от обоих направлений: структуры тем
при LDA/topic2vec/BERTopic и точности полярности при ABSA.