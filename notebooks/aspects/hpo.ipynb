{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import torch\n",
    "\n",
    "from cuml.cluster import HDBSCAN\n",
    "from cuml.manifold import UMAP\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.manifold import trustworthiness\n",
    "import pacmap\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(\"/home/denisalpino/dev/FinABYSS/\")\n",
    "from utils.vizualization import show_feature_importance, show_hpo\n",
    "from utils.metrics import calc_noiseless_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Доступно GPU: {torch.cuda.device_count()}\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading sample of embeddings (10000, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9973, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка sample-выборки эмбеддингов (10000, 768)\n",
    "embeddings = np.load('notebooks/aspects/data/embeddings.npy')\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глоабальная оптимизация гиперпараметров PCA+HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_global(trial):\n",
    "    # Параметры UMAP\n",
    "    umap_n_neighbors = trial.suggest_int(\"umap_n_neighbors\", 5, 100)\n",
    "    umap_min_dist = trial.suggest_float(\"umap_min_dist\", 0.0, 0.5, step=0.01)\n",
    "    umap_n_components = trial.suggest_int(\"umap_n_components\", 10, 80)\n",
    "\n",
    "    # Применяем UMAP прямо к исходным эмбеддингам\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=umap_n_neighbors,\n",
    "        min_dist=umap_min_dist,\n",
    "        n_components=umap_n_components,\n",
    "        metric='cosine'\n",
    "    )\n",
    "    embedding_intermediate = umap_model.fit_transform(embeddings)\n",
    "\n",
    "    # Параметры HDBSCAN\n",
    "    hdbscan_min_cluster_size = trial.suggest_int(\"hdbscan_min_cluster_size\", 5, 100)\n",
    "    hdbscan_min_samples = trial.suggest_int(\"hdbscan_min_samples\", 1, hdbscan_min_cluster_size)\n",
    "    cluster_selection_epsilon = trial.suggest_uniform(\"cluster_selection_epsilon\", 0.0, 1.0)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=hdbscan_min_cluster_size,\n",
    "        min_samples=hdbscan_min_samples,\n",
    "        cluster_selection_method='eom',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embedding_intermediate)\n",
    "\n",
    "    # Вычисляем silhouette score только для ненойзовых точек\n",
    "    valid = labels != -1\n",
    "    if np.sum(valid) < 10 or len(np.unique(labels[valid])) < 2:\n",
    "        return -1.0\n",
    "    score = silhouette_score(embedding_intermediate[valid], labels[valid])\n",
    "    return score\n",
    "\n",
    "print(\"Запускаем глобальную оптимизацию...\")\n",
    "study_global = optuna.create_study(direction=\"maximize\")\n",
    "study_global.optimize(objective_global, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "print(\"Глобальная оптимизация завершена\")\n",
    "print(\"Лучшие глобальные гиперпараметры:\")\n",
    "for key, value in study_global.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"Лучший глобальный silhouette score:\", study_global.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глобальная оптимизация завершена \n",
    "Лучшие глобальные гиперпараметры: \n",
    "* umap_n_neighbors: 48\n",
    "* umap_min_dist: 0.05\n",
    "* umap_n_components: 10\n",
    "* hdbscan_min_cluster_size: 15\n",
    "* hdbscan_min_samples: 11\n",
    "* cluster_selection_epsilon: 0.002172166608873129\n",
    "\n",
    "Лучший глобальный silhouette score: 0.7065192461013794\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Локальная (refined) оптимизация гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_best = study_global.best_params\n",
    "\n",
    "def refined_range(val, delta, low_bound, high_bound):\n",
    "    \"\"\"Функция для вычисления новых диапазонов вокруг глобальных лучших значений\"\"\"\n",
    "    return (max(low_bound, val - delta), min(high_bound, val + delta))\n",
    "\n",
    "# Задаём уточнённые диапазоны:\n",
    "n_neighbors_range = refined_range(global_best[\"umap_n_neighbors\"], 20, 5, 100)\n",
    "min_dist_range = refined_range(global_best[\"umap_min_dist\"], 0.05, 0.0, 0.5)\n",
    "n_components_range = refined_range(global_best[\"umap_n_components\"], 10, 10, 80)\n",
    "hdbscan_cluster_range = refined_range(global_best[\"hdbscan_min_cluster_size\"], 10, 5, 100)\n",
    "\n",
    "def objective_refined(trial):\n",
    "    # Параметры UMAP\n",
    "    umap_n_neighbors = trial.suggest_int(\"umap_n_neighbors\", n_neighbors_range[0], n_neighbors_range[1])\n",
    "    umap_min_dist = trial.suggest_float(\"umap_min_dist\", min_dist_range[0], min_dist_range[1], step=0.01)\n",
    "    umap_n_components = trial.suggest_int(\"umap_n_components\", n_components_range[0], n_components_range[1])\n",
    "\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=umap_n_neighbors,\n",
    "        min_dist=umap_min_dist,\n",
    "        n_components=umap_n_components,\n",
    "        metric=\"cosine\",\n",
    "        random_state=42\n",
    "    )\n",
    "    embedding_intermediate = umap_model.fit_transform(embeddings)\n",
    "\n",
    "    # Параметры HDBSCAN\n",
    "    hdbscan_min_cluster_size = trial.suggest_int(\"hdbscan_min_cluster_size\", hdbscan_cluster_range[0], hdbscan_cluster_range[1])\n",
    "    hdbscan_min_samples = trial.suggest_int(\"hdbscan_min_samples\", 1, hdbscan_min_cluster_size)\n",
    "    cluster_selection_epsilon = trial.suggest_uniform(\"cluster_selection_epsilon\", 0.0, 0.2)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=hdbscan_min_cluster_size,\n",
    "        min_samples=hdbscan_min_samples,\n",
    "        cluster_selection_method='eom',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embedding_intermediate)\n",
    "\n",
    "    valid = labels != -1\n",
    "    if np.sum(valid) < 10 or len(np.unique(labels[valid])) < 2:\n",
    "        return -1.0\n",
    "    score = silhouette_score(embedding_intermediate[valid], labels[valid])\n",
    "    return score\n",
    "\n",
    "print(\"Запускаем уточненную оптимизацию...\")\n",
    "study_refined = optuna.create_study(direction=\"maximize\")\n",
    "study_refined.optimize(objective_refined, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(\"Уточненная оптимизация завершена\")\n",
    "print(\"Лучшие уточненные гиперпараметры:\")\n",
    "for key, value in study_refined.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"Лучший refined silhouette score:\", study_refined.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уточненная оптимизация завершена \n",
    "Лучшие уточненные гиперпараметры:\n",
    "* umap_n_neighbors: 48\n",
    "* umap_min_dist: 0.05\n",
    "* umap_n_components: 15\n",
    "* hdbscan_min_cluster_size: 16\n",
    "* hdbscan_min_samples: 15\n",
    "* cluster_selection_epsilon: 0.022176326579653287\n",
    "\n",
    "Лучший refined silhouette score: 0.7122868299484253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials, fig = show_hpo(\n",
    "    study_global,\n",
    "    \"silhouette_score\",\n",
    "    title=\"HPO combinations for UMAP & HDBSCAN (Random Search)\",\n",
    "    lib=\"optuna\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials.to_csv(\"hpo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальное обучение модели с лучшими (refined) параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 4. Финальное обучение модели с лучшими (refined) параметрами\n",
    "##############################################\n",
    "refined_best = study_refined.best_params\n",
    "\n",
    "# Финальный UMAP на исходных эмбеддингах\n",
    "umap_final = UMAP(\n",
    "    n_neighbors=refined_best[\"umap_n_neighbors\"],\n",
    "    min_dist=refined_best[\"umap_min_dist\"],\n",
    "    n_components=refined_best[\"umap_n_components\"],\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "embedding_intermediate_final = umap_final.fit_transform(embeddings)\n",
    "\n",
    "# Финальная кластеризация HDBSCAN\n",
    "hdbscan_final = HDBSCAN(\n",
    "    min_cluster_size=refined_best[\"hdbscan_min_cluster_size\"],\n",
    "    min_samples=refined_best[\"hdbscan_min_samples\"],\n",
    "    cluster_selection_epsilon=refined_best[\"cluster_selection_epsilon\"],\n",
    "    cluster_selection_method='eom',\n",
    ")\n",
    "final_labels = hdbscan_final.fit_predict(embedding_intermediate_final)\n",
    "n_clusters = len(np.unique(final_labels[final_labels != -1]))\n",
    "n_noise = np.sum(final_labels == -1)\n",
    "print(f\"Финальная кластеризация: кластеров = {n_clusters}, noise = {n_noise} точек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальная кластеризация: кластеров = 86, noise = 3841 точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем данные: рассматриваем только ненойзовые точки\n",
    "mask_valid = final_labels != -1\n",
    "if np.sum(mask_valid) < 2:\n",
    "    print(\"Недостаточно валидных точек для вычисления метрик.\")\n",
    "else:\n",
    "    # Берем промежуточное представление, использованное для финальной кластеризации\n",
    "    X_valid = embedding_intermediate_final[mask_valid]\n",
    "    labels_valid = final_labels[mask_valid]\n",
    "\n",
    "    # Вычисляем метрику Calinski-Harabasz\n",
    "    ch_score = calinski_harabasz_score(X_valid, labels_valid)\n",
    "    # Вычисляем метрику Davies-Bouldin\n",
    "    db_score = davies_bouldin_score(X_valid, labels_valid)\n",
    "\n",
    "    print(f\"Calinski-Harabasz Score: {ch_score:.2f}\")\n",
    "    print(f\"Davies-Bouldin Score: {db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calinski-Harabasz Score: 43867.78  \n",
    "Davies-Bouldin Score: 0.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация итогового 2D графика кластеризации с Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacmap_mapper = pacmap.PaCMAP(n_components=2, random_state=42, MN_ratio=30, FP_ratio=20)\n",
    "embedding_2d = pacmap_mapper.fit_transform(embedding_intermediate_final)\n",
    "# Центрируем 2D-проекцию вокруг [0, 0]\n",
    "embedding_2d_centered = embedding_2d - embedding_2d.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis = pd.DataFrame({\n",
    "    \"Dim1\": embedding_2d_centered[:, 0],\n",
    "    \"Dim2\": embedding_2d_centered[:, 1],\n",
    "    \"Cluster\": final_labels.astype(str)  # преобразуем метки в строку для категорий\n",
    "})\n",
    "\n",
    "fig_clusters = px.scatter(\n",
    "    df_vis,\n",
    "    x=\"Dim1\",\n",
    "    y=\"Dim2\",\n",
    "    color=\"Cluster\",\n",
    "    title=\"2D-проекция кластеризации (PaCMAP)\",\n",
    "    labels={\"Dim1\": \"Dimension 1\", \"Dim2\": \"Dimension 2\"}\n",
    ")\n",
    "fig_clusters.update_layout(legend_title_text=\"Кластер\", height=800)\n",
    "fig_clusters.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray BOHB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandForBOHB\n",
    "from ray.tune.search.bohb import TuneBOHB\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune import JupyterNotebookReporter, Checkpoint, CheckpointConfig\n",
    "from ray.air import session\n",
    "from ray.tune.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_objective(config, embeddings):\n",
    "    reducer = UMAP(\n",
    "        n_neighbors=int(config[\"n_neighbors\"]),\n",
    "        min_dist=config[\"min_dist\"],\n",
    "        n_components=int(config[\"n_components\"]),\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "    embeddings_reduced = reducer.fit_transform(embeddings)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=int(config[\"min_cluster_size\"]),\n",
    "        min_samples=int(config[\"min_samples\"]),\n",
    "        cluster_selection_epsilon=config[\"cluster_selection_epsilon\"],\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        gen_min_span_tree=True,\n",
    "        prediction_data=True\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embeddings_reduced)\n",
    "    score = calc_noiseless_silhouette(embeddings, embeddings_reduced, labels)\n",
    "    tune.report({\n",
    "        \"silhouette_score\": score,\n",
    "        \"umap_model\": reducer,\n",
    "        \"hdbscan_model\": clusterer\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuring tools for HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModels(Callback):\n",
    "    \"\"\"Class for saving the last pair of models with the highest value of metric\"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_score = -float(\"inf\")\n",
    "        self.umap_path = \"/home/denisalpino/ray_results/tune_bohb_umap_hdbscan/umap.pkl\"\n",
    "        self.hdbscan_path = \"/home/denisalpino/ray_results/tune_bohb_umap_hdbscan/hdbscan.pkl\"\n",
    "\n",
    "    def on_trial_result(self, iteration, trial, result, **info):\n",
    "        score = result[\"silhouette_score\"]\n",
    "        if score > self.best_score:\n",
    "            self.best_score = score\n",
    "            reducer = result[\"umap_model\"]\n",
    "            clusterer = result[\"hdbscan_model\"]\n",
    "            with open(self.umap_path, \"wb\") as f: pickle.dump(reducer, f)\n",
    "            with open(self.hdbscan_path, \"wb\") as f: pickle.dump(clusterer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-24 01:32:04</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:41.18        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.7/15.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using HyperBand: num_stopped=0 total_brackets=1<br>Round #0:<br>  Bracket(Max Size (n)=27, Milestone (r)=3, completed=0.5%): {TERMINATED: 2} <br>Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  n_neighbors</th><th style=\"text-align: right;\">  n_components</th><th style=\"text-align: right;\">  min_dist</th><th style=\"text-align: right;\">  min_cluster_size</th><th style=\"text-align: right;\">  min_samples</th><th style=\"text-align: right;\">     cluster_selection_ep\n",
       "silon</th><th style=\"text-align: right;\">  silhouette_score</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>ray_objective_d5e817a4</td><td>TERMINATED</td><td>172.28.84.245:496522</td><td style=\"text-align: right;\">           11</td><td style=\"text-align: right;\">            36</td><td style=\"text-align: right;\">      0.67</td><td style=\"text-align: right;\">                37</td><td style=\"text-align: right;\">           38</td><td style=\"text-align: right;\">0.11</td><td style=\"text-align: right;\">          0.510807</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>ray_objective_e5e73bc0</td><td>TERMINATED</td><td>172.28.84.245:496717</td><td style=\"text-align: right;\">           15</td><td style=\"text-align: right;\">            68</td><td style=\"text-align: right;\">      0.58</td><td style=\"text-align: right;\">                53</td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">0.24</td><td style=\"text-align: right;\">          0.516396</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search space\n",
    "search_space = {\n",
    "    \"n_neighbors\": tune.choice(list(range(10, 60))),\n",
    "    \"n_components\": tune.choice(list(range(10, 75))),\n",
    "    \"min_dist\": tune.choice([i * 0.01 for i in range(0, 75)]),\n",
    "    \"min_cluster_size\": tune.choice(list(range(10, 75))),\n",
    "    \"min_samples\": tune.choice(list(range(5, 40))),\n",
    "    \"cluster_selection_epsilon\": tune.choice([i * 0.01 for i in range(0, 30)]),\n",
    "}\n",
    "\n",
    "# BOHB Search + Scheduler setup\n",
    "bohb_search = ConcurrencyLimiter(TuneBOHB(), max_concurrent=4)\n",
    "bohb_sched = HyperBandForBOHB(time_attr=\"training_iteration\", max_t=100, reduction_factor=4)\n",
    "\n",
    "# Interactive reporter setup\n",
    "reporter = JupyterNotebookReporter(\n",
    "    overwrite=True,\n",
    "    parameter_columns=[\n",
    "        \"n_neighbors\", \"n_components\",\n",
    "        \"min_dist\", \"min_cluster_size\",\n",
    "        \"min_samples\", \"cluster_selection_epsilon\"\n",
    "    ],\n",
    "    metric_columns=[\"silhouette_score\", \"training_iteration\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Launching HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 01:30:23,053\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-04-24 01:31:36,679\tINFO hyperband.py:543 -- Restoring from a previous point in time. Previous=1; Now=1\n",
      "2025-04-24 01:32:02,852\tINFO hyperband.py:543 -- Restoring from a previous point in time. Previous=1; Now=1\n",
      "2025-04-24 01:32:04,246\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/denisalpino/ray_results/tune_bohb_umap_hdbscan' in 1.3815s.\n",
      "2025-04-24 01:32:04,254\tINFO tune.py:1041 -- Total run time: 101.20 seconds (99.79 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "trainable = tune.with_parameters(ray_objective, embeddings=embeddings)\n",
    "\n",
    "bohb_study = tune.run(\n",
    "    trainable,\n",
    "    config=search_space,\n",
    "    metric=\"silhouette_score\",\n",
    "    mode=\"max\",\n",
    "    num_samples=50,\n",
    "    search_alg=bohb_search,\n",
    "    scheduler=bohb_sched,\n",
    "    name=\"tune_bohb_umap_hdbscan\",\n",
    "    verbose=1,\n",
    "    progress_reporter=reporter,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Printing results of optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TuneBOHB complited\n",
      "Clusterization rersults:\n",
      "    clusters = 64,\n",
      "    noise = 1639 observtions\n",
      "The best Noiseless Silhouette score: 0.5164\n",
      "The best hyperparameters:\n",
      "    n_neighbors = 15,\n",
      "    n_components = 68,\n",
      "    min_dist = 0.58,\n",
      "    min_cluster_size = 53,\n",
      "    min_samples = 20,\n",
      "    cluster_selection_epsilon = 0.24,\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_config = bohb_study.best_config\n",
    "best_score = bohb_study.best_result[\"silhouette_score\"]\n",
    "\n",
    "# Load the best pair of models\n",
    "with open(\"/home/denisalpino/ray_results/tune_bohb_umap_hdbscan/umap.pkl\", \"rb\") as f:\n",
    "    umap_best = pickle.load(f)\n",
    "with open(\"/home/denisalpino/ray_results/tune_bohb_umap_hdbscan/hdbscan.pkl\", \"rb\") as f:\n",
    "    hdbscan_best = pickle.load(f)\n",
    "\n",
    "# Calculate number of clusters and noise observtions\n",
    "labels = hdbscan_best.labels_\n",
    "n_clusters = len(np.unique(labels[labels != -1]))\n",
    "n_noise = np.sum(labels == -1)\n",
    "\n",
    "# Results\n",
    "print(\n",
    "    \"TuneBOHB complited\\n\"\n",
    "    \"Clusterization rersults:\\n\"\n",
    "    f\"    clusters = {n_clusters},\\n\"\n",
    "    f\"    noise = {n_noise} observtions\\n\"\n",
    "    f\"The best Noiseless Silhouette score: {best_score:.4f}\\n\"\n",
    "    \"The best hyperparameters:\"\n",
    ")\n",
    "for k, v in best_config.items():\n",
    "    print(f\"    {k} = {v},\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **HPO process vizualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials, fig = show_hpo(\n",
    "    bohb_study,\n",
    "    metric_name=\"silhouette_score\",\n",
    "    title=\"HPO combinations for UMAP & HDBSCAN (Bayesian Optimization with HyperBand)\",\n",
    "    lib=\"ray\",\n",
    "    top_n=50\n",
    ")\n",
    "fig.write_image(file=\"/home/denisalpino/dev/FinABYSS/notebooks/aspects/models/v4/hpo.jpg\", format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>n_components</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>cluster_selection_epsilon</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "      <td>0.58</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.516396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0.67</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.510807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  n_components  min_dist  min_cluster_size  min_samples  \\\n",
       "1           15            68      0.58                53           20   \n",
       "0           11            36      0.67                37           38   \n",
       "\n",
       "   cluster_selection_epsilon  silhouette_score  \n",
       "1                       0.24          0.516396  \n",
       "0                       0.11          0.510807  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = show_feature_importance(df_trials)\n",
    "fig.write_image(file=\"/home/denisalpino/dev/FinABYSS/notebooks/aspects/models/v4/hp_importance.jpg\", format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
