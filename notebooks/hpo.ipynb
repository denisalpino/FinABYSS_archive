{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "\n",
    "from cuml.cluster import HDBSCAN\n",
    "# from cuml.manifold import UMAP\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.manifold import trustworthiness\n",
    "from umap import UMAP\n",
    "import pacmap\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Доступно GPU: {torch.cuda.device_count()}\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка sample-выборки эмбеддингов (10000, 768)\n",
    "embeddings = np.load('embeddings.npy')\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "texts = data.text.to_list()\n",
    "timestamp = data.datetime.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глоабальная оптимизация гиперпараметров PCA+HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_global(trial):\n",
    "    # Параметры UMAP\n",
    "    umap_n_neighbors = trial.suggest_int(\"umap_n_neighbors\", 5, 100)\n",
    "    umap_min_dist = trial.suggest_float(\"umap_min_dist\", 0.0, 0.5, step=0.01)\n",
    "    umap_n_components = trial.suggest_int(\"umap_n_components\", 10, 80)\n",
    "\n",
    "    # Применяем UMAP прямо к исходным эмбеддингам\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=umap_n_neighbors,\n",
    "        min_dist=umap_min_dist,\n",
    "        n_components=umap_n_components,\n",
    "        metric='cosine',\n",
    "        random_state=42\n",
    "    )\n",
    "    embedding_intermediate = umap_model.fit_transform(embeddings)\n",
    "\n",
    "    # Параметры HDBSCAN\n",
    "    hdbscan_min_cluster_size = trial.suggest_int(\"hdbscan_min_cluster_size\", 5, 100)\n",
    "    hdbscan_min_samples = trial.suggest_int(\"hdbscan_min_samples\", 1, hdbscan_min_cluster_size)\n",
    "    cluster_selection_epsilon = trial.suggest_uniform(\"cluster_selection_epsilon\", 0.0, 1.0)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=hdbscan_min_cluster_size,\n",
    "        min_samples=hdbscan_min_samples,\n",
    "        cluster_selection_method='eom',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embedding_intermediate)\n",
    "\n",
    "    # Вычисляем silhouette score только для ненойзовых точек\n",
    "    valid = labels != -1\n",
    "    if np.sum(valid) < 10 or len(np.unique(labels[valid])) < 2:\n",
    "        return -1.0\n",
    "    score = silhouette_score(embedding_intermediate[valid], labels[valid])\n",
    "    return score\n",
    "\n",
    "print(\"Запускаем глобальную оптимизацию...\")\n",
    "study_global = optuna.create_study(direction=\"maximize\")\n",
    "study_global.optimize(objective_global, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "print(\"Глобальная оптимизация завершена\")\n",
    "print(\"Лучшие глобальные гиперпараметры:\")\n",
    "for key, value in study_global.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"Лучший глобальный silhouette score:\", study_global.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глобальная оптимизация завершена \n",
    "Лучшие глобальные гиперпараметры: \n",
    "* umap_n_neighbors: 48\n",
    "* umap_min_dist: 0.05\n",
    "* umap_n_components: 10\n",
    "* hdbscan_min_cluster_size: 15\n",
    "* hdbscan_min_samples: 11\n",
    "* cluster_selection_epsilon: 0.002172166608873129\n",
    "\n",
    "Лучший глобальный silhouette score: 0.7065192461013794\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Локальная (refined) оптимизация гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_best = study_global.best_params\n",
    "\n",
    "def refined_range(val, delta, low_bound, high_bound):\n",
    "    \"\"\"Функция для вычисления новых диапазонов вокруг глобальных лучших значений\"\"\"\n",
    "    return (max(low_bound, val - delta), min(high_bound, val + delta))\n",
    "\n",
    "# Задаём уточнённые диапазоны:\n",
    "n_neighbors_range = refined_range(global_best[\"umap_n_neighbors\"], 20, 5, 100)\n",
    "min_dist_range = refined_range(global_best[\"umap_min_dist\"], 0.05, 0.0, 0.5)\n",
    "n_components_range = refined_range(global_best[\"umap_n_components\"], 10, 10, 80)\n",
    "hdbscan_cluster_range = refined_range(global_best[\"hdbscan_min_cluster_size\"], 10, 5, 100)\n",
    "\n",
    "def objective_refined(trial):\n",
    "    # Параметры UMAP\n",
    "    umap_n_neighbors = trial.suggest_int(\"umap_n_neighbors\", n_neighbors_range[0], n_neighbors_range[1])\n",
    "    umap_min_dist = trial.suggest_float(\"umap_min_dist\", min_dist_range[0], min_dist_range[1], step=0.01)\n",
    "    umap_n_components = trial.suggest_int(\"umap_n_components\", n_components_range[0], n_components_range[1])\n",
    "\n",
    "    umap_model = UMAP(\n",
    "        n_neighbors=umap_n_neighbors,\n",
    "        min_dist=umap_min_dist,\n",
    "        n_components=umap_n_components,\n",
    "        metric=\"cosine\",\n",
    "        random_state=42\n",
    "    )\n",
    "    embedding_intermediate = umap_model.fit_transform(embeddings)\n",
    "\n",
    "    # Параметры HDBSCAN\n",
    "    hdbscan_min_cluster_size = trial.suggest_int(\"hdbscan_min_cluster_size\", hdbscan_cluster_range[0], hdbscan_cluster_range[1])\n",
    "    hdbscan_min_samples = trial.suggest_int(\"hdbscan_min_samples\", 1, hdbscan_min_cluster_size)\n",
    "    cluster_selection_epsilon = trial.suggest_uniform(\"cluster_selection_epsilon\", 0.0, 0.2)\n",
    "\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=hdbscan_min_cluster_size,\n",
    "        min_samples=hdbscan_min_samples,\n",
    "        cluster_selection_method='eom',\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embedding_intermediate)\n",
    "\n",
    "    valid = labels != -1\n",
    "    if np.sum(valid) < 10 or len(np.unique(labels[valid])) < 2:\n",
    "        return -1.0\n",
    "    score = silhouette_score(embedding_intermediate[valid], labels[valid])\n",
    "    return score\n",
    "\n",
    "print(\"Запускаем уточненную оптимизацию...\")\n",
    "study_refined = optuna.create_study(direction=\"maximize\")\n",
    "study_refined.optimize(objective_refined, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(\"Уточненная оптимизация завершена\")\n",
    "print(\"Лучшие уточненные гиперпараметры:\")\n",
    "for key, value in study_refined.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"Лучший refined silhouette score:\", study_refined.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уточненная оптимизация завершена \n",
    "Лучшие уточненные гиперпараметры:\n",
    "* umap_n_neighbors: 48\n",
    "* umap_min_dist: 0.05\n",
    "* umap_n_components: 15\n",
    "* hdbscan_min_cluster_size: 16\n",
    "* hdbscan_min_samples: 15\n",
    "* cluster_selection_epsilon: 0.022176326579653287\n",
    "\n",
    "Лучший refined silhouette score: 0.7122868299484253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 3. Визуалзация оптимизации гиперпараметров (глобальная оптимизация) с Plotly\n",
    "##############################################\n",
    "# Собираем историю глобальной оптимизации\n",
    "records = []\n",
    "for trial in study_global.trials:\n",
    "    if trial.state.name != \"COMPLETE\":\n",
    "        continue\n",
    "    rec = trial.params.copy()\n",
    "    rec[\"silhouette_score\"] = trial.value\n",
    "    records.append(rec)\n",
    "for trial in study_refined.trials:\n",
    "    if trial.state.name != \"COMPLETE\":\n",
    "        continue\n",
    "    rec = trial.params.copy()\n",
    "    rec[\"silhouette_score\"] = trial.value\n",
    "    records.append(rec)\n",
    "\n",
    "df_trials = pd.DataFrame(records)\n",
    "\n",
    "# Преобразуем все подходящие столбцы в числовой тип\n",
    "for col in df_trials.columns:\n",
    "    try:\n",
    "        df_trials[col] = pd.to_numeric(df_trials[col])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "fig_parallel = px.parallel_coordinates(\n",
    "    df_trials[df_trials.silhouette_score > 0.64],\n",
    "    color=\"silhouette_score\",\n",
    "    labels={\n",
    "        \"umap_n_neighbors\": \"UMAP n_neighbors\",\n",
    "        \"umap_min_dist\": \"UMAP min_dist\",\n",
    "        \"umap_n_components\": \"UMAP n_components\",\n",
    "        \"hdbscan_min_cluster_size\": \"HDBSCAN min_cluster_size\",\n",
    "        \"hdbscan_min_samples\": \"HDBSCAN min_samples\",\n",
    "        \"silhouette_score\": \"Silhouette\"\n",
    "    },\n",
    "    color_continuous_scale=px.colors.sequential.Inferno,\n",
    "    title=\"Глобальная оптимизация гиперпараметров (UMAP + HDBSCAN)\",\n",
    "    template=\"plotly_dark\",\n",
    "    height=800\n",
    ")\n",
    "fig_parallel.show()\n",
    "df_trials[df_trials.silhouette_score > 0.64].sort_values(\"silhouette_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials.to_csv(\"hpo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальное обучение модели с лучшими (refined) параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 4. Финальное обучение модели с лучшими (refined) параметрами\n",
    "##############################################\n",
    "refined_best = study_refined.best_params\n",
    "\n",
    "# Финальный UMAP на исходных эмбеддингах\n",
    "umap_final = UMAP(\n",
    "    n_neighbors=refined_best[\"umap_n_neighbors\"],\n",
    "    min_dist=refined_best[\"umap_min_dist\"],\n",
    "    n_components=refined_best[\"umap_n_components\"],\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "embedding_intermediate_final = umap_final.fit_transform(embeddings)\n",
    "\n",
    "# Финальная кластеризация HDBSCAN\n",
    "hdbscan_final = HDBSCAN(\n",
    "    min_cluster_size=refined_best[\"hdbscan_min_cluster_size\"],\n",
    "    min_samples=refined_best[\"hdbscan_min_samples\"],\n",
    "    cluster_selection_epsilon=refined_best[\"cluster_selection_epsilon\"],\n",
    "    cluster_selection_method='eom',\n",
    ")\n",
    "final_labels = hdbscan_final.fit_predict(embedding_intermediate_final)\n",
    "n_clusters = len(np.unique(final_labels[final_labels != -1]))\n",
    "n_noise = np.sum(final_labels == -1)\n",
    "print(f\"Финальная кластеризация: кластеров = {n_clusters}, noise = {n_noise} точек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальная кластеризация: кластеров = 86, noise = 3841 точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем данные: рассматриваем только ненойзовые точки\n",
    "mask_valid = final_labels != -1\n",
    "if np.sum(mask_valid) < 2:\n",
    "    print(\"Недостаточно валидных точек для вычисления метрик.\")\n",
    "else:\n",
    "    # Берем промежуточное представление, использованное для финальной кластеризации\n",
    "    X_valid = embedding_intermediate_final[mask_valid]\n",
    "    labels_valid = final_labels[mask_valid]\n",
    "\n",
    "    # Вычисляем метрику Calinski-Harabasz\n",
    "    ch_score = calinski_harabasz_score(X_valid, labels_valid)\n",
    "    # Вычисляем метрику Davies-Bouldin\n",
    "    db_score = davies_bouldin_score(X_valid, labels_valid)\n",
    "\n",
    "    print(f\"Calinski-Harabasz Score: {ch_score:.2f}\")\n",
    "    print(f\"Davies-Bouldin Score: {db_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calinski-Harabasz Score: 43867.78  \n",
    "Davies-Bouldin Score: 0.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация итогового 2D графика кластеризации с Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacmap_mapper = pacmap.PaCMAP(n_components=2, random_state=42, MN_ratio=30, FP_ratio=20)\n",
    "embedding_2d = pacmap_mapper.fit_transform(embedding_intermediate_final)\n",
    "# Центрируем 2D-проекцию вокруг [0, 0]\n",
    "embedding_2d_centered = embedding_2d - embedding_2d.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis = pd.DataFrame({\n",
    "    \"Dim1\": embedding_2d_centered[:, 0],\n",
    "    \"Dim2\": embedding_2d_centered[:, 1],\n",
    "    \"Cluster\": final_labels.astype(str)  # преобразуем метки в строку для категорий\n",
    "})\n",
    "\n",
    "fig_clusters = px.scatter(\n",
    "    df_vis,\n",
    "    x=\"Dim1\",\n",
    "    y=\"Dim2\",\n",
    "    color=\"Cluster\",\n",
    "    title=\"2D-проекция кластеризации (PaCMAP)\",\n",
    "    labels={\"Dim1\": \"Dimension 1\", \"Dim2\": \"Dimension 2\"}\n",
    ")\n",
    "fig_clusters.update_layout(legend_title_text=\"Кластер\", height=800)\n",
    "fig_clusters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
